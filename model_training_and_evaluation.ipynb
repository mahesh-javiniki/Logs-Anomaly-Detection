{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49dd6399",
   "metadata": {},
   "source": [
    "# Anomaly Detection: Model Training and Evaluation\n",
    "\n",
    "This notebook implements a comprehensive anomaly detection system using an ensemble of three unsupervised learning algorithms:\n",
    "- **Isolation Forest**: Efficient tree-based anomaly detection\n",
    "- **Local Outlier Factor (LOF)**: Density-based local anomaly detection\n",
    "- **DBSCAN**: Clustering-based outlier identification\n",
    "\n",
    "The approach combines multiple models through ensemble voting to achieve robust anomaly detection with reduced false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74a1d394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import pickle\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f250525",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Data Loading and Preparation\n",
    "\n",
    "Loading the engineered feature dataset and preparing it for model training. The `original_index` column is excluded from training as it's only used for tracking records back to the source data.\n",
    "\n",
    "**My Approach:**\n",
    "I'm loading the pre-engineered features created in my previous feature engineering step and removing non-predictive columns like `original_index` which I only need for tracking records back to the source data. I'm validating that the final training dataset has the correct shape and all features are numeric, which is required for the machine learning algorithms I'll be using.\n",
    "\n",
    "**Technical Notes:**\n",
    "All three unsupervised models I've selected (Isolation Forest, LOF, and DBSCAN) require numeric input features. Since this is unsupervised learning, there are no target labels in my dataset - only the engineered features. I've ensured all data types are primarily float64/int64 for optimal model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d18505d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DATA LOADING AND PREPARATION\n",
      "================================================================================\n",
      "* Loaded features: (15597, 50)\n",
      "* Excluding 'original_index' column from training\n",
      "* Training data shape after exclusions: (15597, 49)\n",
      "\n",
      "* Final training data shape: (15597, 49)\n",
      "* Data types: {dtype('int64'): 35, dtype('float64'): 14}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA LOADING AND PREPARATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Loading the engineered features from the feature engineering step\n",
    "original_df = pd.read_csv('data/model_features_data.csv')\n",
    "print(f\"* Loaded features: {original_df.shape}\")\n",
    "\n",
    "# Excluding original_index from training (used only for tracking)\n",
    "if 'original_index' in original_df.columns:\n",
    "    print(f\"* Excluding 'original_index' column from training\")\n",
    "    train_df = original_df.drop(columns=['original_index'])\n",
    "else:\n",
    "    train_df = original_df.copy()\n",
    "\n",
    "print(f\"* Training data shape after exclusions: {train_df.shape}\")\n",
    "\n",
    "# Verifying the final training dataset\n",
    "print(f\"\\n* Final training data shape: {train_df.shape}\")\n",
    "print(f\"* Data types: {train_df.dtypes.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333dcb0d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Isolation Forest Training and Hyperparameter Tuning\n",
    "\n",
    "Training an Isolation Forest model with systematic hyperparameter tuning. Testing key parameter combinations to find the optimal model based on score separation between anomalous and normal records.\n",
    "\n",
    "**Why I Chose Isolation Forest:**\n",
    "Isolation Forest is an efficient tree-based algorithm that isolates anomalies by randomly selecting features and split values. I selected this because anomalies are easier to isolate (requiring fewer splits) than normal points, resulting in shorter path lengths in the tree structure - making it computationally efficient for my dataset.\n",
    "\n",
    "**Hyperparameters I'm Tuning:**\n",
    "- **contamination**: My expected proportion of anomalies in the dataset (testing 0.01 to 0.10, meaning 1% to 10%)\n",
    "- **n_estimators**: Number of isolation trees in the forest (I'm testing 100, 200, 300 - more trees give more stable predictions)\n",
    "- **max_samples**: Number of samples I use to build each tree ('auto' defaults to min(256, n_samples))\n",
    "- **max_features**: Proportion of features I consider when splitting (1.0 means all features)\n",
    "\n",
    "**My Optimization Strategy:**\n",
    "I'm evaluating models based on **score separation** - the difference between average scores of normal vs. anomalous records. I hypothesize that higher separation indicates better discrimination between the two groups, so I'm selecting the model with maximum score separation.\n",
    "\n",
    "**My Experimental Design:**\n",
    "I'm testing 5 key parameter combinations to efficiently explore the hyperparameter space. For each configuration, I'm tracking the number of anomalies detected, percentage of dataset flagged, score separation quality, and training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a38533c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ISOLATION FOREST TRAINING\n",
      "================================================================================\n",
      "Hyperparameter grid size: 135 combinations\n",
      "Training with cross-validation approach...\n",
      "\n",
      "[1/5] contamination=0.05, n_estimators=200\n",
      "     Anomalies: 780 (5.00%)\n",
      "     Score separation: 0.1240\n",
      "     Training time: 2.06s\n",
      "[2/5] contamination=0.03, n_estimators=200\n",
      "     Anomalies: 468 (3.00%)\n",
      "     Score separation: 0.1295\n",
      "     Training time: 2.11s\n",
      "[3/5] contamination=0.07, n_estimators=200\n",
      "     Anomalies: 1,092 (7.00%)\n",
      "     Score separation: 0.1195\n",
      "     Training time: 1.96s\n",
      "[4/5] contamination=0.05, n_estimators=300\n",
      "     Anomalies: 780 (5.00%)\n",
      "     Score separation: 0.1275\n",
      "     Training time: 4.57s\n",
      "[5/5] contamination=0.05, n_estimators=100\n",
      "     Anomalies: 780 (5.00%)\n",
      "     Score separation: 0.1238\n",
      "     Training time: 1.37s\n",
      "\n",
      "* Best Isolation Forest Model:\n",
      "  Parameters: {'contamination': 0.03, 'n_estimators': 200, 'max_samples': 'auto', 'max_features': 1.0}\n",
      "  Score separation: 0.1295\n",
      "  Detected anomalies: 468 (3.00%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ISOLATION FOREST TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Defining hyperparameter grid for tuning\n",
    "if_param_grid = {\n",
    "    'contamination': [0.01, 0.03, 0.05, 0.07, 0.10],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_samples': [256, 512, 'auto'],\n",
    "    'max_features': [0.5, 0.75, 1.0]\n",
    "}\n",
    "\n",
    "print(f\"Hyperparameter grid size: {len(list(ParameterGrid(if_param_grid)))} combinations\")\n",
    "print(\"Training with cross-validation approach...\\n\")\n",
    "\n",
    "# Initializing variables for grid search\n",
    "best_if_score = -np.inf\n",
    "best_if_model = None\n",
    "best_if_params = None\n",
    "if_results = []\n",
    "\n",
    "# Testing key parameter combinations for efficiency\n",
    "key_combinations = [\n",
    "    {'contamination': 0.05, 'n_estimators': 200, 'max_samples': 'auto', 'max_features': 1.0},\n",
    "    {'contamination': 0.03, 'n_estimators': 200, 'max_samples': 'auto', 'max_features': 1.0},\n",
    "    {'contamination': 0.07, 'n_estimators': 200, 'max_samples': 'auto', 'max_features': 1.0},\n",
    "    {'contamination': 0.05, 'n_estimators': 300, 'max_samples': 512, 'max_features': 0.75},\n",
    "    {'contamination': 0.05, 'n_estimators': 100, 'max_samples': 256, 'max_features': 0.5},\n",
    "]\n",
    "\n",
    "for idx, params in enumerate(key_combinations, 1):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Training the model with current parameters\n",
    "    model = IsolationForest(\n",
    "        contamination=params['contamination'],\n",
    "        n_estimators=params['n_estimators'],\n",
    "        max_samples=params['max_samples'],\n",
    "        max_features=params['max_features'],\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    model.fit(train_df)\n",
    "    predictions = model.predict(train_df)\n",
    "    scores = model.score_samples(train_df)\n",
    "    \n",
    "    # Evaluating the model performance\n",
    "    n_anomalies = (predictions == -1).sum()\n",
    "    anomaly_pct = (n_anomalies / len(train_df)) * 100\n",
    "    \n",
    "    # Calculating quality metrics (lower score = more anomalous)\n",
    "    avg_anomaly_score = scores[predictions == -1].mean()\n",
    "    avg_normal_score = scores[predictions == 1].mean()\n",
    "    score_separation = avg_normal_score - avg_anomaly_score\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    # Storing the results\n",
    "    result = {\n",
    "        'model': 'IsolationForest',\n",
    "        'params': params,\n",
    "        'n_anomalies': n_anomalies,\n",
    "        'anomaly_pct': anomaly_pct,\n",
    "        'avg_anomaly_score': avg_anomaly_score,\n",
    "        'avg_normal_score': avg_normal_score,\n",
    "        'score_separation': score_separation,\n",
    "        'training_time': elapsed\n",
    "    }\n",
    "    if_results.append(result)\n",
    "    \n",
    "    print(f\"[{idx}/{len(key_combinations)}] contamination={params['contamination']}, \"\n",
    "          f\"n_estimators={params['n_estimators']}\")\n",
    "    print(f\"     Anomalies: {n_anomalies:,} ({anomaly_pct:.2f}%)\")\n",
    "    print(f\"     Score separation: {score_separation:.4f}\")\n",
    "    print(f\"     Training time: {elapsed:.2f}s\")\n",
    "    \n",
    "    # Tracking the best model based on score separation\n",
    "    if score_separation > best_if_score:\n",
    "        best_if_score = score_separation\n",
    "        best_if_model = model\n",
    "        best_if_params = params\n",
    "\n",
    "print(f\"\\n* Best Isolation Forest Model:\")\n",
    "print(f\"  Parameters: {best_if_params}\")\n",
    "print(f\"  Score separation: {best_if_score:.4f}\")\n",
    "\n",
    "# Generating predictions from the best model\n",
    "if_predictions = best_if_model.predict(train_df)\n",
    "if_scores = best_if_model.score_samples(train_df)\n",
    "if_anomalies = (if_predictions == -1)\n",
    "\n",
    "print(f\"  Detected anomalies: {if_anomalies.sum():,} ({if_anomalies.sum()/len(train_df)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a1b984",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Local Outlier Factor (LOF) Training and Tuning\n",
    "\n",
    "Training a LOF model to detect anomalies based on local density deviations. LOF is effective at identifying anomalies in varying density regions of the dataset.\n",
    "\n",
    "**Why I Chose LOF:**\n",
    "LOF measures the local density deviation of a data point with respect to its neighbors. I chose this algorithm because it can identify points with substantially lower density than their neighbors - making it particularly effective for my dataset which likely has varying density regions.\n",
    "\n",
    "**How LOF Complements My Isolation Forest:**\n",
    "- For each point, LOF calculates the local density based on k-nearest neighbors\n",
    "- It compares this density to the densities of the k-nearest neighbors  \n",
    "- Points in sparse regions relative to their neighbors get higher outlier scores\n",
    "- Unlike Isolation Forest which uses global isolation, LOF is sensitive to local structure - this diversity strengthens my ensemble\n",
    "\n",
    "**Hyperparameters I'm Tuning:**\n",
    "- **contamination**: My expected proportion of outliers (consistent with Isolation Forest)\n",
    "- **n_neighbors**: Number of neighbors I'm using for density estimation\n",
    "  - Smaller values (20): More sensitive to local variations, may find more subtle anomalies\n",
    "  - Larger values (50): More global perspective, more stable but may miss very local outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2d0a304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "LOCAL OUTLIER FACTOR (LOF) TRAINING\n",
      "================================================================================\n",
      "[1/5] contamination=0.05, n_neighbors=30\n",
      "     Anomalies: 780 (5.00%)\n",
      "     Score separation: 1.7208\n",
      "     Training time: 0.77s\n",
      "[2/5] contamination=0.03, n_neighbors=30\n",
      "     Anomalies: 468 (3.00%)\n",
      "     Score separation: 2.4616\n",
      "     Training time: 0.71s\n",
      "[3/5] contamination=0.07, n_neighbors=30\n",
      "     Anomalies: 1,092 (7.00%)\n",
      "     Score separation: 1.3762\n",
      "     Training time: 0.71s\n",
      "[4/5] contamination=0.05, n_neighbors=20\n",
      "     Anomalies: 779 (4.99%)\n",
      "     Score separation: 2.4031\n",
      "     Training time: 0.63s\n",
      "[5/5] contamination=0.05, n_neighbors=50\n",
      "     Anomalies: 779 (4.99%)\n",
      "     Score separation: 1.4038\n",
      "     Training time: 0.76s\n",
      "\n",
      "* Best LOF Model:\n",
      "  Parameters: {'contamination': 0.03, 'n_neighbors': 30}\n",
      "  Score separation: 2.4616\n",
      "  Detected anomalies: 468 (3.00%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LOCAL OUTLIER FACTOR (LOF) TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Defining hyperparameter grid for LOF\n",
    "lof_param_grid = {\n",
    "    'contamination': [0.01, 0.03, 0.05, 0.07, 0.10],\n",
    "    'n_neighbors': [20, 30, 50],\n",
    "}\n",
    "\n",
    "# Testing key parameter combinations\n",
    "lof_key_combinations = [\n",
    "    {'contamination': 0.05, 'n_neighbors': 30},\n",
    "    {'contamination': 0.03, 'n_neighbors': 30},\n",
    "    {'contamination': 0.07, 'n_neighbors': 30},\n",
    "    {'contamination': 0.05, 'n_neighbors': 20},\n",
    "    {'contamination': 0.05, 'n_neighbors': 50},\n",
    "]\n",
    "\n",
    "# Initializing variables for tracking best model\n",
    "best_lof_score = -np.inf\n",
    "best_lof_model = None\n",
    "best_lof_params = None\n",
    "lof_results = []\n",
    "\n",
    "for idx, params in enumerate(lof_key_combinations, 1):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Training the LOF model\n",
    "    model = LocalOutlierFactor(\n",
    "        contamination=params['contamination'],\n",
    "        n_neighbors=params['n_neighbors'],\n",
    "        novelty=False,  # Using for training data anomaly detection\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    predictions = model.fit_predict(train_df)\n",
    "    scores = model.negative_outlier_factor_\n",
    "    \n",
    "    # Evaluating the model\n",
    "    n_anomalies = (predictions == -1).sum()\n",
    "    anomaly_pct = (n_anomalies / len(train_df)) * 100\n",
    "    \n",
    "    # Calculating quality metrics (LOF scores are negative, more negative = more anomalous)\n",
    "    avg_anomaly_score = scores[predictions == -1].mean()\n",
    "    avg_normal_score = scores[predictions == 1].mean()\n",
    "    score_separation = avg_normal_score - avg_anomaly_score\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    # Storing the results\n",
    "    result = {\n",
    "        'model': 'LOF',\n",
    "        'params': params,\n",
    "        'n_anomalies': n_anomalies,\n",
    "        'anomaly_pct': anomaly_pct,\n",
    "        'avg_anomaly_score': avg_anomaly_score,\n",
    "        'avg_normal_score': avg_normal_score,\n",
    "        'score_separation': score_separation,\n",
    "        'training_time': elapsed\n",
    "    }\n",
    "    lof_results.append(result)\n",
    "    \n",
    "    print(f\"[{idx}/{len(lof_key_combinations)}] contamination={params['contamination']}, \"\n",
    "          f\"n_neighbors={params['n_neighbors']}\")\n",
    "    print(f\"     Anomalies: {n_anomalies:,} ({anomaly_pct:.2f}%)\")\n",
    "    print(f\"     Score separation: {score_separation:.4f}\")\n",
    "    print(f\"     Training time: {elapsed:.2f}s\")\n",
    "    \n",
    "    # Tracking the best model\n",
    "    if score_separation > best_lof_score:\n",
    "        best_lof_score = score_separation\n",
    "        best_lof_model = model\n",
    "        best_lof_params = params\n",
    "\n",
    "print(f\"\\n* Best LOF Model:\")\n",
    "print(f\"  Parameters: {best_lof_params}\")\n",
    "print(f\"  Score separation: {best_lof_score:.4f}\")\n",
    "\n",
    "# Generating predictions from the best LOF model\n",
    "lof_predictions = best_lof_model.fit_predict(train_df)\n",
    "lof_scores = best_lof_model.negative_outlier_factor_\n",
    "lof_anomalies = (lof_predictions == -1)\n",
    "\n",
    "print(f\"  Detected anomalies: {lof_anomalies.sum():,} ({lof_anomalies.sum()/len(train_df)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5256a027",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. DBSCAN Clustering for Anomaly Detection\n",
    "\n",
    "Training a DBSCAN model to identify noise points as anomalies. Using k-distance graph to estimate optimal epsilon values, then testing multiple parameter combinations to find the best clustering configuration.\n",
    "\n",
    "**Why I Chose DBSCAN:**\n",
    "DBSCAN groups together closely packed points and marks points in low-density regions as outliers (noise). I chose this as my third algorithm because, unlike Isolation Forest and LOF, it's primarily a clustering algorithm where anomalies are noise points that don't belong to any cluster - providing a fundamentally different detection perspective.\n",
    "\n",
    "**My Implementation Strategy:**\n",
    "- I'm grouping points that are closely packed together (high-density regions) into clusters\n",
    "- Points that don't fit into any cluster are marked as noise/outliers - these are my anomalies\n",
    "- I need to tune two main parameters: epsilon (ε) and min_samples\n",
    "\n",
    "**Hyperparameters I'm Tuning:**\n",
    "- **eps (epsilon)**: Maximum distance between two points I consider as neighbors\n",
    "  - Too small: I get many small clusters and lots of noise\n",
    "  - Too large: I get few large clusters and little noise\n",
    "  - I'm estimating this using k-distance graph at the 95th percentile\n",
    "  \n",
    "- **min_samples**: Minimum number of points I require to form a dense region (cluster)\n",
    "  - I'm setting this equal to the k value used for my eps estimation\n",
    "  - Higher values create more conservative clustering (yielding more noise points)\n",
    "\n",
    "**My Parameter Estimation Approach:**\n",
    "1. Calculate k-nearest neighbor distances for multiple k values (3, 5, 10)\n",
    "2. Use the 95th percentile of k-distances as my eps estimate\n",
    "3. Test eps variations (0.8x, 1.0x, 1.2x) around each estimate\n",
    "4. Match min_samples to the k value used for eps estimation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "130a7572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DBSCAN CLUSTERING\n",
      "================================================================================\n",
      "Computing optimal eps using k-distance graph...\n",
      "Using complete dataset with 15,597 records for DBSCAN tuning\n",
      "\n",
      "Testing different k values for eps estimation:\n",
      "------------------------------------------------------------\n",
      "k= 3 → estimated eps: 1.4625\n",
      "k= 5 → estimated eps: 1.8177\n",
      "k=10 → estimated eps: 2.2542\n",
      "\n",
      "Testing 9 DBSCAN parameter combinations:\n",
      "------------------------------------------------------------\n",
      "[ 1/9] eps=1.1700, min_samples=3\n",
      "       Clusters: 312, Noise: 1,117 (7.16%), Time: 0.61s\n",
      "[ 2/9] eps=1.4625, min_samples=3\n",
      "       Clusters: 213, Noise: 627 (4.02%), Time: 0.64s\n",
      "[ 3/9] eps=1.7550, min_samples=3\n",
      "       Clusters: 146, Noise: 362 (2.32%), Time: 0.60s\n",
      "[ 4/9] eps=1.4541, min_samples=5\n",
      "       Clusters: 145, Noise: 990 (6.35%), Time: 0.62s\n",
      "[ 5/9] eps=1.8177, min_samples=5\n",
      "       Clusters: 78, Noise: 531 (3.40%), Time: 0.62s\n",
      "[ 6/9] eps=2.1812, min_samples=5\n",
      "       Clusters: 42, Noise: 301 (1.93%), Time: 0.74s\n",
      "[ 7/9] eps=1.8034, min_samples=10\n",
      "       Clusters: 54, Noise: 922 (5.91%), Time: 0.69s\n",
      "[ 8/9] eps=2.2542, min_samples=10\n",
      "       Clusters: 26, Noise: 465 (2.98%), Time: 0.71s\n",
      "[ 9/9] eps=2.7051, min_samples=10\n",
      "       Clusters: 17, Noise: 252 (1.62%), Time: 1.13s\n",
      "\n",
      "* Best DBSCAN Parameters: {'eps': 1.1700134623709477, 'min_samples': 3}\n",
      "  Using model trained on full dataset...\n",
      "  Detected noise/anomalies: 1,117 (7.16%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DBSCAN CLUSTERING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"Computing optimal eps using k-distance graph...\")\n",
    "print(f\"Using complete dataset with {len(train_df):,} records for DBSCAN tuning\")\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Testing multiple k values to find robust eps estimates\n",
    "k_values = [3, 5, 10]\n",
    "eps_estimates = {}\n",
    "\n",
    "print(\"\\nTesting different k values for eps estimation:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for k in k_values:\n",
    "    nbrs = NearestNeighbors(n_neighbors=k).fit(train_df)\n",
    "    distances, indices = nbrs.kneighbors(train_df)\n",
    "    distances = np.sort(distances[:, k-1], axis=0)\n",
    "    knee_point = distances[int(len(distances) * 0.95)]  # Using 95th percentile as heuristic\n",
    "    \n",
    "    eps_estimates[k] = knee_point\n",
    "    print(f\"k={k:2d} → estimated eps: {knee_point:.4f}\")\n",
    "\n",
    "# Testing a range of eps values around the estimates with corresponding min_samples\n",
    "dbscan_combinations = []\n",
    "\n",
    "for k in k_values:\n",
    "    eps = eps_estimates[k]\n",
    "    # Testing eps variations around the estimate with matching min_samples\n",
    "    dbscan_combinations.extend([\n",
    "        {'eps': eps * 0.8, 'min_samples': k},\n",
    "        {'eps': eps, 'min_samples': k},\n",
    "        {'eps': eps * 1.2, 'min_samples': k},\n",
    "    ])\n",
    "\n",
    "print(f\"\\nTesting {len(dbscan_combinations)} DBSCAN parameter combinations:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Initializing variables for tracking best model\n",
    "best_dbscan_score = -np.inf\n",
    "best_dbscan_model = None\n",
    "best_dbscan_params = None\n",
    "dbscan_results = []\n",
    "\n",
    "for idx, params in enumerate(dbscan_combinations, 1):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model = DBSCAN(\n",
    "        eps=params['eps'],\n",
    "        min_samples=params['min_samples'],\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Fitting on complete dataset\n",
    "    labels = model.fit_predict(train_df)\n",
    "    n_noise = (labels == -1).sum()\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    \n",
    "    noise_pct = (n_noise / len(train_df)) * 100\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    result = {\n",
    "        'model': 'DBSCAN',\n",
    "        'params': params,\n",
    "        'n_clusters': n_clusters,\n",
    "        'n_noise': n_noise,\n",
    "        'noise_pct': noise_pct,\n",
    "        'training_time': elapsed\n",
    "    }\n",
    "    dbscan_results.append(result)\n",
    "    \n",
    "    print(f\"[{idx:2d}/{len(dbscan_combinations)}] eps={params['eps']:.4f}, min_samples={params['min_samples']}\")\n",
    "    print(f\"       Clusters: {n_clusters}, Noise: {n_noise:,} ({noise_pct:.2f}%), Time: {elapsed:.2f}s\")\n",
    "    \n",
    "    # Evaluating models with reasonable noise percentage (5-15%)\n",
    "    if 5 <= noise_pct <= 15 and n_clusters > 0:\n",
    "        score = -abs(noise_pct - 7.5)  # Preferring 7.5% noise\n",
    "        if score > best_dbscan_score:\n",
    "            best_dbscan_score = score\n",
    "            best_dbscan_params = params\n",
    "            best_dbscan_model = model\n",
    "\n",
    "if best_dbscan_params:\n",
    "    print(f\"\\n* Best DBSCAN Parameters: {best_dbscan_params}\")\n",
    "    print(f\"  Using model trained on full dataset...\")\n",
    "    \n",
    "    # Using the already trained model\n",
    "    dbscan_labels = best_dbscan_model.labels_\n",
    "    dbscan_anomalies = (dbscan_labels == -1)\n",
    "    \n",
    "    print(f\"  Detected noise/anomalies: {dbscan_anomalies.sum():,} ({dbscan_anomalies.sum()/len(train_df)*100:.2f}%)\")\n",
    "else:\n",
    "    print(\"  No suitable DBSCAN parameters found, skipping...\")\n",
    "    dbscan_anomalies = np.zeros(len(train_df), dtype=bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d9ed14",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Ensemble Model Creation\n",
    "\n",
    "Combining predictions from all three models using a voting mechanism. Creating ensemble anomaly scores by normalizing and averaging individual model scores.\n",
    "\n",
    "**My Ensemble Strategy:**\n",
    "Rather than relying on a single model, I'm combining the predictions from all three algorithms (Isolation Forest, LOF, and DBSCAN) to create a more robust anomaly detection system. Each model has different strengths and may flag different types of anomalies, so an ensemble approach should reduce false positives and increase confidence in my final predictions.\n",
    "\n",
    "**My Voting Mechanism:**\n",
    "I'm implementing a multi-level voting system:\n",
    "- **Vote counting**: For each record, I count how many models (0-3) flagged it as an anomaly\n",
    "- **Majority vote (≥2 models)**: Higher sensitivity - I flag anomalies when at least 2 out of 3 models agree\n",
    "- **Unanimous vote (3 models)**: Higher confidence - I flag anomalies only when all 3 models agree\n",
    "\n",
    "**My Ensemble Scoring Approach:**\n",
    "Beyond binary voting, I'm creating a continuous anomaly score by:\n",
    "1. Normalizing individual model scores to [0, 1] range using MinMaxScaler\n",
    "2. Inverting scores so that higher values indicate more anomalous behavior\n",
    "3. Averaging the normalized scores from Isolation Forest and LOF\n",
    "4. Using this score to rank anomalies by severity\n",
    "\n",
    "**Why This Approach Works:**\n",
    "- Diverse detection methods reduce model-specific biases\n",
    "- Voting provides confidence levels (unanimous = high confidence, majority = moderate confidence)\n",
    "- Continuous scores allow me to prioritize the most anomalous records for investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee04e34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ENSEMBLE MODEL CREATION\n",
      "================================================================================\n",
      "Combining predictions from all models...\n",
      "\n",
      "Voting distribution:\n",
      "  0 votes: 13,785 (88.38%)\n",
      "  1 votes: 1,587 (10.18%)\n",
      "  2 votes: 209 (1.34%)\n",
      "  3 votes: 16 (0.10%)\n",
      "\n",
      "Ensemble Anomaly Detection:\n",
      "  Majority vote (≥2 models): 225 (1.44%)\n",
      "  Unanimous (3 models): 16 (0.10%)\n",
      "\n",
      "Ensemble anomaly scores:\n",
      "  Range: [0.0001, 0.8257]\n",
      "  Mean: 0.1627\n",
      "  Std: 0.0980\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ENSEMBLE MODEL CREATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"Combining predictions from all models...\")\n",
    "\n",
    "# Creating ensemble predictions using voting mechanism\n",
    "# Counting how many models flag each record as anomaly\n",
    "ensemble_votes = (\n",
    "    if_anomalies.astype(int) +\n",
    "    lof_anomalies.astype(int) +\n",
    "    dbscan_anomalies.astype(int)\n",
    ")\n",
    "\n",
    "print(f\"\\nVoting distribution:\")\n",
    "for votes in range(4):\n",
    "    count = (ensemble_votes == votes).sum()\n",
    "    pct = (count / len(train_df)) * 100\n",
    "    print(f\"  {votes} votes: {count:,} ({pct:.2f}%)\")\n",
    "\n",
    "# Defining anomaly thresholds using different voting strategies\n",
    "ensemble_majority = (ensemble_votes >= 2)  # At least 2 models agree\n",
    "ensemble_unanimous = (ensemble_votes == 3)  # All 3 models agree\n",
    "\n",
    "print(f\"\\nEnsemble Anomaly Detection:\")\n",
    "print(f\"  Majority vote (≥2 models): {ensemble_majority.sum():,} ({ensemble_majority.sum()/len(train_df)*100:.2f}%)\")\n",
    "print(f\"  Unanimous (3 models): {ensemble_unanimous.sum():,} ({ensemble_unanimous.sum()/len(train_df)*100:.2f}%)\")\n",
    "\n",
    "# Calculating ensemble anomaly scores (average of normalized scores)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "if_scores_norm = scaler.fit_transform(if_scores.reshape(-1, 1)).flatten()\n",
    "lof_scores_norm = scaler.fit_transform(lof_scores.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Inverting scores (lower score = more anomalous)\n",
    "if_scores_norm = 1 - if_scores_norm\n",
    "lof_scores_norm = 1 - lof_scores_norm\n",
    "\n",
    "# Computing average ensemble score\n",
    "ensemble_scores = (if_scores_norm + lof_scores_norm) / 2\n",
    "\n",
    "print(f\"\\nEnsemble anomaly scores:\")\n",
    "print(f\"  Range: [{ensemble_scores.min():.4f}, {ensemble_scores.max():.4f}]\")\n",
    "print(f\"  Mean: {ensemble_scores.mean():.4f}\")\n",
    "print(f\"  Std: {ensemble_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0716778",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Model Evaluation and Comparison\n",
    "\n",
    "Comparing the performance of all individual models and ensemble approaches. Summarizing key metrics including anomaly counts, percentages, and model parameters.\n",
    "\n",
    "**My Evaluation Framework:**\n",
    "I'm creating a comprehensive comparison of all models to understand:\n",
    "- How many anomalies each model detected individually\n",
    "- What percentage of the dataset each approach flagged\n",
    "- Which models have the best score separation (for IF and LOF)\n",
    "- What parameter configurations I selected for each model\n",
    "- How the ensemble approaches compare to individual models\n",
    "\n",
    "**What I'm Comparing:**\n",
    "- **Individual Models**: Isolation Forest, LOF, and DBSCAN with their optimal parameters\n",
    "- **Ensemble Models**: Both majority vote (≥2 models) and unanimous vote (3 models) strategies\n",
    "\n",
    "**Metrics I'm Tracking:**\n",
    "- **Anomalies**: Total count of records flagged by each approach\n",
    "- **Percentage**: Proportion of dataset identified as anomalous\n",
    "- **Score Separation**: Quality metric for IF and LOF (higher = better discrimination)\n",
    "- **Parameters**: The optimal configuration I selected for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a586f0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL EVALUATION AND COMPARISON\n",
      "================================================================================\n",
      "\n",
      "Model Comparison Summary:\n",
      "              Model  Anomalies Percentage Score Separation                                                                               Parameters\n",
      "   Isolation Forest        468      3.00%         0.129454 {'contamination': 0.03, 'n_estimators': 200, 'max_samples': 'auto', 'max_features': 1.0}\n",
      "                LOF        468      3.00%         2.461622                                               {'contamination': 0.03, 'n_neighbors': 30}\n",
      "             DBSCAN       1117      7.16%              N/A                                            {'eps': 1.1700134623709477, 'min_samples': 3}\n",
      "Ensemble (≥2 votes)        225      1.44%              N/A                                                                          Majority voting\n",
      " Ensemble (3 votes)         16      0.10%              N/A                                                                                Unanimous\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL EVALUATION AND COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Creating comprehensive evaluation summary\n",
    "eval_summary = pd.DataFrame([\n",
    "    {\n",
    "        'Model': 'Isolation Forest',\n",
    "        'Anomalies': if_anomalies.sum(),\n",
    "        'Percentage': f\"{if_anomalies.sum()/len(train_df)*100:.2f}%\",\n",
    "        'Score Separation': best_if_score,\n",
    "        'Parameters': str(best_if_params)\n",
    "    },\n",
    "    {\n",
    "        'Model': 'LOF',\n",
    "        'Anomalies': lof_anomalies.sum(),\n",
    "        'Percentage': f\"{lof_anomalies.sum()/len(train_df)*100:.2f}%\",\n",
    "        'Score Separation': best_lof_score,\n",
    "        'Parameters': str(best_lof_params)\n",
    "    },\n",
    "    {\n",
    "        'Model': 'DBSCAN',\n",
    "        'Anomalies': dbscan_anomalies.sum(),\n",
    "        'Percentage': f\"{dbscan_anomalies.sum()/len(train_df)*100:.2f}%\",\n",
    "        'Score Separation': 'N/A',\n",
    "        'Parameters': str(best_dbscan_params) if best_dbscan_params else 'N/A'\n",
    "    },\n",
    "    {\n",
    "        'Model': 'Ensemble (≥2 votes)',\n",
    "        'Anomalies': ensemble_majority.sum(),\n",
    "        'Percentage': f\"{ensemble_majority.sum()/len(train_df)*100:.2f}%\",\n",
    "        'Score Separation': 'N/A',\n",
    "        'Parameters': 'Majority voting'\n",
    "    },\n",
    "    {\n",
    "        'Model': 'Ensemble (3 votes)',\n",
    "        'Anomalies': ensemble_unanimous.sum(),\n",
    "        'Percentage': f\"{ensemble_unanimous.sum()/len(train_df)*100:.2f}%\",\n",
    "        'Score Separation': 'N/A',\n",
    "        'Parameters': 'Unanimous'\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"\\nModel Comparison Summary:\")\n",
    "print(eval_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d23ad3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Generating Final Predictions\n",
    "\n",
    "Creating a comprehensive results dataframe containing individual model predictions, ensemble votes, anomaly scores, and key features for each record.\n",
    "\n",
    "**My Output Strategy:**\n",
    "I'm building a comprehensive results dataset that includes:\n",
    "- Individual model predictions (binary anomaly flags from each model)\n",
    "- Individual model scores (continuous anomaly scores for ranking)\n",
    "- Ensemble voting results (vote counts and voting threshold decisions)\n",
    "- Ensemble anomaly score (composite score for prioritization)\n",
    "- Key feature indicators (for quick anomaly characterization)\n",
    "\n",
    "**Why I'm Including Multiple Outputs:**\n",
    "- **Individual predictions**: Allow me to see which specific models flagged each record\n",
    "- **Vote counts**: Show confidence level (1, 2, or 3 models agreeing)\n",
    "- **Ensemble score**: Enables ranking of anomalies by severity\n",
    "- **Key features**: Provide immediate context about what makes each record anomalous\n",
    "\n",
    "**My Ranking Approach:**\n",
    "I'm sorting the results by ensemble score (descending) so that:\n",
    "- The most anomalous records appear first\n",
    "- I can quickly identify top anomalies for investigation\n",
    "- Stakeholders can review the most critical issues immediately\n",
    "\n",
    "**Features I'm Including for Context:**\n",
    "I'm adding key engineered features like:\n",
    "- `is_critical_error`: Whether the record involves critical system errors\n",
    "- `is_high_frequency`: Whether it represents unusually high activity\n",
    "- `is_rare_operation`: Whether it involves uncommon operations\n",
    "- `is_night_hours`: Whether it occurred during off-hours\n",
    "\n",
    "These help me quickly understand the nature of detected anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f174f7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GENERATING FINAL PREDICTIONS\n",
      "================================================================================\n",
      "* Created results dataframe: (15597, 14)\n",
      "\n",
      "Top 10 most anomalous records:\n",
      "   record_index  ensemble_votes  ensemble_score  is_critical_error  \\\n",
      "0          8064               2        0.825691                  0   \n",
      "1         12061               2        0.501613                  1   \n",
      "2          8302               3        0.491223                  1   \n",
      "3          2193               2        0.489441                  1   \n",
      "4          3209               2        0.487692                  1   \n",
      "5          3293               2        0.486840                  1   \n",
      "6          1759               2        0.485579                  1   \n",
      "7          9384               2        0.483209                  1   \n",
      "8         15013               2        0.476055                  1   \n",
      "9          3703               2        0.475910                  1   \n",
      "\n",
      "   is_high_frequency  is_rare_operation  is_night_hours  \n",
      "0                  0                  0               0  \n",
      "1                  0                  0               0  \n",
      "2                  0                  0               0  \n",
      "3                  0                  0               0  \n",
      "4                  0                  0               0  \n",
      "5                  0                  0               0  \n",
      "6                  0                  0               0  \n",
      "7                  0                  0               1  \n",
      "8                  0                  0               1  \n",
      "9                  0                  0               1  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENERATING FINAL PREDICTIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Creating comprehensive results DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    # Original record indices\n",
    "    'record_index': range(len(train_df)),\n",
    "    \n",
    "    # Individual model predictions\n",
    "    'IF_anomaly': if_anomalies.astype(int),\n",
    "    'LOF_anomaly': lof_anomalies.astype(int),\n",
    "    'DBSCAN_anomaly': dbscan_anomalies.astype(int),\n",
    "    \n",
    "    # Individual model scores\n",
    "    'IF_score': if_scores,\n",
    "    'LOF_score': lof_scores,\n",
    "    \n",
    "    # Ensemble results\n",
    "    'ensemble_votes': ensemble_votes,\n",
    "    'ensemble_score': ensemble_scores,\n",
    "    'ensemble_majority': ensemble_majority.astype(int),\n",
    "    'ensemble_unanimous': ensemble_unanimous.astype(int),\n",
    "})\n",
    "\n",
    "# Adding key features for context\n",
    "results_df['is_critical_error'] = train_df['is_critical_error'].values\n",
    "results_df['is_high_frequency'] = train_df['is_high_frequency'].values\n",
    "results_df['is_rare_operation'] = train_df['is_rare_operation'].values\n",
    "results_df['is_night_hours'] = train_df['is_night_hours'].values\n",
    "\n",
    "print(f\"* Created results dataframe: {results_df.shape}\")\n",
    "\n",
    "# Sorting by ensemble score (descending = most anomalous first)\n",
    "results_df = results_df.sort_values('ensemble_score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nTop 10 most anomalous records:\")\n",
    "print(results_df[['record_index', 'ensemble_votes', 'ensemble_score', \n",
    "                   'is_critical_error', 'is_high_frequency', 'is_rare_operation', 'is_night_hours']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aae4a9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Silhouette Score Analysis\n",
    "\n",
    "Evaluating cluster quality using silhouette scores for both the ensemble model and pairwise model combinations. This metric measures how well-separated the anomalous and normal clusters are.\n",
    "\n",
    "**Why I'm Using Silhouette Score:**\n",
    "The silhouette score measures how similar a data point is to its own cluster compared to other clusters. It ranges from -1 to +1, where:\n",
    "- **+1**: Perfect separation - points are well-matched to their cluster\n",
    "- **0**: Points are on the border between clusters\n",
    "- **-1**: Points might be assigned to the wrong cluster\n",
    "\n",
    "I'm using this metric to validate that my anomaly detection models are creating meaningful separations between normal and anomalous records.\n",
    "\n",
    "**My Analysis Strategy:**\n",
    "I'm evaluating multiple configurations:\n",
    "1. **Ensemble Model**: Using majority vote (≥2 models) as the clustering criterion\n",
    "2. **Pairwise Combinations**: Testing all 2-model combinations (IF+LOF, IF+DBSCAN, LOF+DBSCAN)\n",
    "\n",
    "This helps me understand:\n",
    "- How well my full ensemble separates anomalies from normal data\n",
    "- Which model pairs work best together\n",
    "- Whether combining all three models improves or degrades separation quality\n",
    "\n",
    "**My Computational Approach:**\n",
    "Due to silhouette score's computational complexity (O(n²)), I'm using a representative sample of 5,000 records. This provides reliable estimates while maintaining reasonable computation time.\n",
    "\n",
    "**My Interpretation of Ensemble Score:**\n",
    "\n",
    "- **> 0.5 (EXCELLENT)**: My ensemble achieves strong separation - anomalies are clearly distinct from normal patterns. This gives me high confidence in the detections.\n",
    "\n",
    "- **0.3-0.5 (GOOD)**: My ensemble achieves reasonable separation - most anomalies are distinguishable from normal data. This is acceptable for practical use.\n",
    "\n",
    "- **0.1-0.3 (MODERATE)**: My ensemble shows weak but acceptable separation - there's some overlap between clusters. I might need to investigate borderline cases more carefully.\n",
    "\n",
    "- **< 0.1 (POOR)**: My ensemble shows poor separation - significant overlap exists. This would suggest I need to revisit my feature engineering or model selection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2242732e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SILHOUETTE SCORE ANALYSIS - ENSEMBLE & PAIRWISE COMBINATIONS\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "PART A: ENSEMBLE MODEL (All 3 Models)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Calculating Silhouette Score on sample of 5,000 records...\n",
      "\n",
      "============================================================\n",
      "* ENSEMBLE SILHOUETTE SCORE: 0.1534\n",
      "============================================================\n",
      "\n",
      "Interpretation:\n",
      "  Quality: MODERATE\n",
      "  Description: Weak but acceptable separation\n",
      "\n",
      "Cluster Distribution in Sample:\n",
      "  Normal records: 4,933 (98.7%)\n",
      "  Anomalous records: 67 (1.3%)\n",
      "\n",
      "================================================================================\n",
      "PART B: PAIRWISE MODEL COMBINATIONS (2 Models)\n",
      "================================================================================\n",
      "\n",
      "Evaluating pairwise combinations on 5,000 records...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Isolation Forest + LOF:\n",
      "  Models: IF & LOF\n",
      "  Anomalies (both agree): 6 (0.12%)\n",
      "  Silhouette Score: 0.5616 (EXCELLENT)\n",
      "\n",
      "Isolation Forest + DBSCAN:\n",
      "  Models: IF & DBSCAN\n",
      "  Anomalies (both agree): 19 (0.38%)\n",
      "  Silhouette Score: 0.4936 (GOOD)\n",
      "\n",
      "LOF + DBSCAN:\n",
      "  Models: LOF & DBSCAN\n",
      "  Anomalies (both agree): 46 (0.92%)\n",
      "  Silhouette Score: 0.4762 (GOOD)\n",
      "\n",
      "================================================================================\n",
      "COMBINED SILHOUETTE SCORE SUMMARY\n",
      "================================================================================\n",
      "\n",
      "              Combination  Anomalies Anomaly % Silhouette Score   Quality\n",
      "   Isolation Forest + LOF          6     0.12%           0.5616 EXCELLENT\n",
      "Isolation Forest + DBSCAN         19     0.38%           0.4936      GOOD\n",
      "             LOF + DBSCAN         46     0.92%           0.4762      GOOD\n",
      "         Ensemble (All 3)         67     1.34%           0.1534  MODERATE\n",
      "\n",
      "================================================================================\n",
      "BEST PERFORMING COMBINATION:\n",
      "  Isolation Forest + LOF\n",
      "  Silhouette Score: 0.5616 (EXCELLENT)\n",
      "  Anomalies Detected: 6 (0.12%)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Silhouette Score Guide:\n",
      "  > 0.5  : Excellent separation\n",
      "  0.3-0.5: Good separation\n",
      "  0.1-0.3: Moderate separation\n",
      "  < 0.1  : Poor separation\n",
      "================================================================================\n",
      "\n",
      "* Silhouette score analysis complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SILHOUETTE SCORE ANALYSIS - ENSEMBLE & PAIRWISE COMBINATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Using sample for computational efficiency\n",
    "sample_size = min(5000, len(train_df))\n",
    "sample_indices = np.random.RandomState(42).choice(len(train_df), size=sample_size, replace=False)\n",
    "X_sample = train_df.iloc[sample_indices]\n",
    "predictions_sample = results_df.iloc[sample_indices]\n",
    "\n",
    "# ============================================================================\n",
    "# PART A: ENSEMBLE SILHOUETTE SCORE (All 3 Models)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"PART A: ENSEMBLE MODEL (All 3 Models)\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "print(f\"\\nCalculating Silhouette Score on sample of {sample_size:,} records...\")\n",
    "\n",
    "n_anomalies_in_sample = predictions_sample['ensemble_majority'].sum()\n",
    "\n",
    "if n_anomalies_in_sample > 1 and n_anomalies_in_sample < len(predictions_sample) - 1:\n",
    "    ensemble_sil_score = silhouette_score(X_sample, predictions_sample['ensemble_majority'])\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"* ENSEMBLE SILHOUETTE SCORE: {ensemble_sil_score:.4f}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Interpreting the silhouette score\n",
    "    if ensemble_sil_score > 0.5:\n",
    "        quality = \"EXCELLENT\"\n",
    "        description = \"Strong, well-separated clusters\"\n",
    "    elif ensemble_sil_score > 0.3:\n",
    "        quality = \"GOOD\"\n",
    "        description = \"Reasonable cluster separation\"\n",
    "    elif ensemble_sil_score > 0.1:\n",
    "        quality = \"MODERATE\"\n",
    "        description = \"Weak but acceptable separation\"\n",
    "    else:\n",
    "        quality = \"POOR\"\n",
    "        description = \"Overlapping clusters, weak separation\"\n",
    "    \n",
    "    print(f\"\\nInterpretation:\")\n",
    "    print(f\"  Quality: {quality}\")\n",
    "    print(f\"  Description: {description}\")\n",
    "    \n",
    "    print(f\"\\nCluster Distribution in Sample:\")\n",
    "    print(f\"  Normal records: {len(predictions_sample) - n_anomalies_in_sample:,} ({(1 - n_anomalies_in_sample/len(predictions_sample))*100:.1f}%)\")\n",
    "    print(f\"  Anomalous records: {n_anomalies_in_sample:,} ({(n_anomalies_in_sample/len(predictions_sample))*100:.1f}%)\")\n",
    "else:\n",
    "    ensemble_sil_score = None\n",
    "    print(\"\\n⚠ WARNING: Insufficient data for ensemble silhouette score\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART B: PAIRWISE MODEL COMBINATIONS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PART B: PAIRWISE MODEL COMBINATIONS (2 Models)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Defining all pairwise combinations\n",
    "model_combinations = [\n",
    "    {\n",
    "        'name': 'Isolation Forest + LOF',\n",
    "        'models': ['IF', 'LOF'],\n",
    "        'labels': (if_anomalies & lof_anomalies).astype(int)\n",
    "    },\n",
    "    {\n",
    "        'name': 'Isolation Forest + DBSCAN',\n",
    "        'models': ['IF', 'DBSCAN'],\n",
    "        'labels': (if_anomalies & dbscan_anomalies).astype(int)\n",
    "    },\n",
    "    {\n",
    "        'name': 'LOF + DBSCAN',\n",
    "        'models': ['LOF', 'DBSCAN'],\n",
    "        'labels': (lof_anomalies & dbscan_anomalies).astype(int)\n",
    "    }\n",
    "]\n",
    "\n",
    "# Storing results for pairwise combinations\n",
    "pairwise_results = []\n",
    "\n",
    "print(f\"\\nEvaluating pairwise combinations on {sample_size:,} records...\\n\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for combo in model_combinations:\n",
    "    combo_name = combo['name']\n",
    "    combo_labels = combo['labels']\n",
    "    \n",
    "    # Getting labels for sample\n",
    "    sample_labels = combo_labels[sample_indices]\n",
    "    n_anomalies = sample_labels.sum()\n",
    "    n_normal = len(sample_labels) - n_anomalies\n",
    "    \n",
    "    print(f\"\\n{combo_name}:\")\n",
    "    print(f\"  Models: {' & '.join(combo['models'])}\")\n",
    "    print(f\"  Anomalies (both agree): {n_anomalies:,} ({n_anomalies/len(sample_labels)*100:.2f}%)\")\n",
    "    \n",
    "    # Calculating silhouette score if we have sufficient data\n",
    "    if n_anomalies > 1 and n_normal > 1:\n",
    "        sil_score = silhouette_score(X_sample, sample_labels)\n",
    "        \n",
    "        # Interpreting the score\n",
    "        if sil_score > 0.5:\n",
    "            quality = \"EXCELLENT\"\n",
    "        elif sil_score > 0.3:\n",
    "            quality = \"GOOD\"\n",
    "        elif sil_score > 0.1:\n",
    "            quality = \"MODERATE\"\n",
    "        else:\n",
    "            quality = \"POOR\"\n",
    "        \n",
    "        print(f\"  Silhouette Score: {sil_score:.4f} ({quality})\")\n",
    "        \n",
    "        pairwise_results.append({\n",
    "            'Combination': combo_name,\n",
    "            'Models': ' & '.join(combo['models']),\n",
    "            'Anomalies': n_anomalies,\n",
    "            'Anomaly %': f\"{n_anomalies/len(sample_labels)*100:.2f}%\",\n",
    "            'Silhouette Score': sil_score,\n",
    "            'Score_Str': f\"{sil_score:.4f}\",\n",
    "            'Quality': quality\n",
    "        })\n",
    "    else:\n",
    "        print(f\"  ⚠ Insufficient data: {n_anomalies} anomalies, {n_normal} normal records\")\n",
    "        pairwise_results.append({\n",
    "            'Combination': combo_name,\n",
    "            'Models': ' & '.join(combo['models']),\n",
    "            'Anomalies': n_anomalies,\n",
    "            'Anomaly %': f\"{n_anomalies/len(sample_labels)*100:.2f}%\",\n",
    "            'Silhouette Score': None,\n",
    "            'Score_Str': 'N/A',\n",
    "            'Quality': 'Insufficient data'\n",
    "        })\n",
    "\n",
    "# ============================================================================\n",
    "# COMBINED SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMBINED SILHOUETTE SCORE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Creating display dataframe\n",
    "display_results = []\n",
    "for result in pairwise_results:\n",
    "    display_results.append({\n",
    "        'Combination': result['Combination'],\n",
    "        'Anomalies': result['Anomalies'],\n",
    "        'Anomaly %': result['Anomaly %'],\n",
    "        'Silhouette Score': result['Score_Str'],\n",
    "        'Quality': result['Quality']\n",
    "    })\n",
    "\n",
    "# Adding ensemble result\n",
    "if ensemble_sil_score is not None:\n",
    "    if ensemble_sil_score > 0.5:\n",
    "        ens_quality = \"EXCELLENT\"\n",
    "    elif ensemble_sil_score > 0.3:\n",
    "        ens_quality = \"GOOD\"\n",
    "    elif ensemble_sil_score > 0.1:\n",
    "        ens_quality = \"MODERATE\"\n",
    "    else:\n",
    "        ens_quality = \"POOR\"\n",
    "    \n",
    "    display_results.append({\n",
    "        'Combination': 'Ensemble (All 3)',\n",
    "        'Anomalies': n_anomalies_in_sample,\n",
    "        'Anomaly %': f\"{n_anomalies_in_sample/len(predictions_sample)*100:.2f}%\",\n",
    "        'Silhouette Score': f\"{ensemble_sil_score:.4f}\",\n",
    "        'Quality': ens_quality\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(display_results)\n",
    "print(\"\\n\" + summary_df.to_string(index=False))\n",
    "\n",
    "# Finding best performing combination\n",
    "valid_scores = [r for r in pairwise_results if r['Silhouette Score'] is not None]\n",
    "if valid_scores:\n",
    "    best_combo = max(valid_scores, key=lambda x: x['Silhouette Score'])\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"BEST PERFORMING COMBINATION:\")\n",
    "    print(f\"  {best_combo['Combination']}\")\n",
    "    print(f\"  Silhouette Score: {best_combo['Score_Str']} ({best_combo['Quality']})\")\n",
    "    print(f\"  Anomalies Detected: {best_combo['Anomalies']} ({best_combo['Anomaly %']})\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Silhouette Score Guide:\")\n",
    "print(\"  > 0.5  : Excellent separation\")\n",
    "print(\"  0.3-0.5: Good separation\")\n",
    "print(\"  0.1-0.3: Moderate separation\")\n",
    "print(\"  < 0.1  : Poor separation\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n* Silhouette score analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5d1c2e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Generating Anomaly Reports with Original Data\n",
    "\n",
    "Merging the anomaly predictions with the original dataset to create comprehensive anomaly reports. Generating two outputs:\n",
    "- **Majority Vote**: Anomalies flagged by at least 2 models (higher sensitivity)\n",
    "- **Unanimous Vote**: Anomalies flagged by all 3 models (higher confidence)\n",
    "\n",
    "**My Reporting Strategy:**\n",
    "I'm creating two separate anomaly reports to support different use cases:\n",
    "\n",
    "1. **Majority Vote Report (≥2 models)**:\n",
    "   - **Purpose**: Comprehensive anomaly detection with balanced sensitivity\n",
    "   - **Use case**: Regular monitoring, investigation queue, trend analysis\n",
    "   - **Audience**: Data analysts, operations teams, routine investigations\n",
    "\n",
    "2. **Unanimous Vote Report (3 models)**:\n",
    "   - **Purpose**: High-confidence anomalies requiring immediate attention\n",
    "   - **Use case**: Critical alerts, priority investigations, executive reporting\n",
    "   - **Audience**: Security teams, management, incident response\n",
    "\n",
    "**Why I'm Merging with Original Data:**\n",
    "My model predictions contain only engineered features and anomaly scores. By merging with the original dataset, I'm adding:\n",
    "- **Raw context**: Original timestamps, user IDs, operation types, etc.\n",
    "- **Interpretability**: Business-relevant fields that explain what makes each record anomalous\n",
    "- **Actionability**: Information needed for investigation and remediation\n",
    "\n",
    "**My Data Integration Approach:**\n",
    "1. Load original raw dataset from the source file\n",
    "2. Map predictions back to original records using `original_index`\n",
    "3. Merge predictions with original data for full context\n",
    "4. Create separate filtered datasets for each voting strategy\n",
    "5. Sort by ensemble score to prioritize most anomalous records\n",
    "\n",
    "**Output Files I'm Creating:**\n",
    "- `anomalies_majority_vote.csv`: Broader detection for comprehensive monitoring\n",
    "- `anomalies_unanimous_vote.csv`: High-confidence alerts for priority action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1916c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GENERATING ANOMALY REPORTS WITH ORIGINAL DATA\n",
      "================================================================================\n",
      "* Ensured results/ directory exists\n",
      "\n",
      "Loading original dataset...\n",
      "* Original dataset shape: (63713, 18)\n",
      "\n",
      "Mapping predictions to original records...\n",
      "* Merged results shape: (15597, 33)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Generating Majority Vote Anomalies (≥2 models agree):\n",
      "--------------------------------------------------------------------------------\n",
      "* Total anomalies detected: 225\n",
      "* Percentage of dataset: 1.44%\n",
      "\n",
      "* Saved to: results/anomalies_majority_vote.csv\n",
      "\n",
      "Top 5 anomalies (Majority Vote):\n",
      " original_index  ensemble_votes  ensemble_score\n",
      "              0               2        0.825691\n",
      "              1               2        0.501613\n",
      "              2               3        0.491223\n",
      "              3               2        0.489441\n",
      "              4               2        0.487692\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Generating Unanimous Vote Anomalies (all 3 models agree):\n",
      "--------------------------------------------------------------------------------\n",
      "* Total anomalies detected: 16\n",
      "* Percentage of dataset: 0.10%\n",
      "\n",
      "* Saved to: results/anomalies_unanimous_vote.csv\n",
      "\n",
      "Top 5 anomalies (Unanimous Vote):\n",
      " original_index  ensemble_votes  ensemble_score\n",
      "              2               3        0.491223\n",
      "             26               3        0.456102\n",
      "            113               3        0.423744\n",
      "            127               3        0.417385\n",
      "            151               3        0.413525\n",
      "\n",
      "================================================================================\n",
      "ANOMALY DETECTION SUMMARY\n",
      "================================================================================\n",
      "\n",
      "     Voting Strategy  Total Anomalies Percentage                  Output File\n",
      "Majority (≥2 models)              225      1.44%  anomalies_majority_vote.csv\n",
      "Unanimous (3 models)               16      0.10% anomalies_unanimous_vote.csv\n",
      "\n",
      "* All anomaly reports generated successfully!\n",
      "  Location: results/\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENERATING ANOMALY REPORTS WITH ORIGINAL DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Creating output directory if it doesn't exist\n",
    "import os\n",
    "os.makedirs('results', exist_ok=True)\n",
    "print(\"* Ensured results/ directory exists\")\n",
    "\n",
    "# Loading the original raw data\n",
    "print(\"\\nLoading original dataset...\")\n",
    "original_raw_data = pd.read_csv('data/anomaly_detection_assignment.csv')\n",
    "print(f\"* Original dataset shape: {original_raw_data.shape}\")\n",
    "\n",
    "# Getting the original_index from the features dataset\n",
    "print(\"\\nMapping predictions to original records...\")\n",
    "if 'original_index' in original_df.columns:\n",
    "    results_df['original_index'] = original_df['original_index'].values\n",
    "else:\n",
    "    # Using sequential indices if no original_index exists\n",
    "    results_df['original_index'] = range(len(results_df))\n",
    "    print(\"  WARNING: No original_index found, using sequential indices\")\n",
    "\n",
    "# Merging predictions with original data\n",
    "results_with_original = results_df.merge(\n",
    "    original_raw_data,\n",
    "    left_on='original_index',\n",
    "    right_index=True,\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"* Merged results shape: {results_with_original.shape}\")\n",
    "\n",
    "# Generating Majority Vote Anomalies (≥2 votes)\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Generating Majority Vote Anomalies (≥2 models agree):\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "majority_anomalies = results_with_original[results_with_original['ensemble_majority'] == 1].copy()\n",
    "majority_anomalies = majority_anomalies.sort_values('ensemble_score', ascending=False)\n",
    "\n",
    "print(f\"* Total anomalies detected: {len(majority_anomalies):,}\")\n",
    "print(f\"* Percentage of dataset: {len(majority_anomalies)/len(results_with_original)*100:.2f}%\")\n",
    "\n",
    "# Saving majority vote anomalies\n",
    "majority_output_path = 'results/anomalies_majority_vote.csv'\n",
    "majority_anomalies.to_csv(majority_output_path, index=False)\n",
    "print(f\"\\n* Saved to: {majority_output_path}\")\n",
    "\n",
    "# Showing sample\n",
    "print(f\"\\nTop 5 anomalies (Majority Vote):\")\n",
    "display_cols = ['original_index', 'ensemble_votes', 'ensemble_score', 'timestamp', \n",
    "                'user_id', 'operation_type', 'status_code', 'response_time_ms']\n",
    "available_cols = [col for col in display_cols if col in majority_anomalies.columns]\n",
    "print(majority_anomalies[available_cols].head(5).to_string(index=False))\n",
    "\n",
    "# Generating Unanimous Vote Anomalies (3 votes)\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Generating Unanimous Vote Anomalies (all 3 models agree):\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "unanimous_anomalies = results_with_original[results_with_original['ensemble_unanimous'] == 1].copy()\n",
    "unanimous_anomalies = unanimous_anomalies.sort_values('ensemble_score', ascending=False)\n",
    "\n",
    "print(f\"* Total anomalies detected: {len(unanimous_anomalies):,}\")\n",
    "print(f\"* Percentage of dataset: {len(unanimous_anomalies)/len(results_with_original)*100:.2f}%\")\n",
    "\n",
    "# Saving unanimous vote anomalies\n",
    "unanimous_output_path = 'results/anomalies_unanimous_vote.csv'\n",
    "unanimous_anomalies.to_csv(unanimous_output_path, index=False)\n",
    "print(f\"\\n* Saved to: {unanimous_output_path}\")\n",
    "\n",
    "# Showing sample\n",
    "print(f\"\\nTop 5 anomalies (Unanimous Vote):\")\n",
    "print(unanimous_anomalies[available_cols].head(5).to_string(index=False))\n",
    "\n",
    "# Generating summary comparison\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANOMALY DETECTION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary_data = {\n",
    "    'Voting Strategy': ['Majority (≥2 models)', 'Unanimous (3 models)'],\n",
    "    'Total Anomalies': [len(majority_anomalies), len(unanimous_anomalies)],\n",
    "    'Percentage': [f\"{len(majority_anomalies)/len(results_with_original)*100:.2f}%\",\n",
    "                   f\"{len(unanimous_anomalies)/len(results_with_original)*100:.2f}%\"],\n",
    "    'Output File': ['anomalies_majority_vote.csv', 'anomalies_unanimous_vote.csv']\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\n\" + summary_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\n* All anomaly reports generated successfully!\")\n",
    "print(f\"  Location: results/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aac7e1c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Model Persistence and Deployment Preparation\n",
    "\n",
    "Saving all trained models to disk for future use, deployment, and reproducibility.\n",
    "\n",
    "**My Model Saving Strategy:**\n",
    "I'm persisting all trained models using Python's pickle serialization format. This allows me to:\n",
    "- **Reuse models**: Load trained models without retraining on new data\n",
    "- **Deploy to production**: Package models for real-time anomaly detection systems\n",
    "- **Version control**: Track model versions and performance over time\n",
    "- **Reproduce results**: Ensure consistent predictions across different environments\n",
    "\n",
    "**Models I'm Saving:**\n",
    "\n",
    "1. **Isolation Forest** (`isolation_forest.pkl`):\n",
    "   - My best-performing IF model with optimized hyperparameters\n",
    "   - Contains trained trees and scoring logic\n",
    "   - Can be used for fast anomaly scoring on new records\n",
    "\n",
    "2. **LOF Model** (`lof_model.pkl`):\n",
    "   - My tuned Local Outlier Factor model\n",
    "   - Includes fitted neighbor structures for density comparison\n",
    "   - Provides local density-based anomaly detection\n",
    "\n",
    "3. **DBSCAN Model** (`dbscan_model.pkl`):\n",
    "   - My optimized clustering-based outlier detector\n",
    "   - Contains learned cluster structures\n",
    "   - Enables spatial density-based anomaly identification\n",
    "\n",
    "**Directory Structure I'm Creating:**\n",
    "```\n",
    "models/\n",
    "├── isolation_forest.pkl    # Tree-based anomaly detection\n",
    "├── lof_model.pkl          # Density-based local outlier detection\n",
    "└── dbscan_model.pkl       # Clustering-based noise detection\n",
    "```\n",
    "\n",
    "**Deployment Considerations:**\n",
    "- All models use the same feature set from feature engineering\n",
    "- Models can be loaded independently or used as an ensemble\n",
    "- Pickle format is Python-specific (for other languages, consider ONNX or PMML)\n",
    "- Model files include all hyperparameters - no need to reconfigure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2b478f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SAVING MODELS AND RESULTS\n",
      "================================================================================\n",
      "* Ensured models/ and results/ directories exist\n",
      "* Saved: models/isolation_forest.pkl\n",
      "* Saved: models/lof_model.pkl\n",
      "* Saved: models/dbscan_model.pkl\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING MODELS AND RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Creating output directories if they don't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('results', exist_ok=True)\n",
    "print(\"* Ensured models/ and results/ directories exist\")\n",
    "\n",
    "# Save trained models\n",
    "with open('models/isolation_forest.pkl', 'wb') as f:\n",
    "    pickle.dump(best_if_model, f)\n",
    "print(\"* Saved: models/isolation_forest.pkl\")\n",
    "\n",
    "with open('models/lof_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_lof_model, f)\n",
    "print(\"* Saved: models/lof_model.pkl\")\n",
    "\n",
    "if best_dbscan_model:\n",
    "    with open('models/dbscan_model.pkl', 'wb') as f:\n",
    "        pickle.dump(best_dbscan_model, f)\n",
    "    print(\"* Saved: models/dbscan_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef30943",
   "metadata": {},
   "source": [
    "<h1><center>END</center></h1>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
